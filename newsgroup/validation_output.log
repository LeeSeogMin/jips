
================================================================================
20 Newsgroups Validation Experiment
Manuscript Section 5.X: Public Dataset Validation
================================================================================

================================================================================
Loading 20 Newsgroups Dataset
================================================================================

Dataset Statistics:
  Total documents: 1000
  Category distribution:
    - Computer: 200 docs
    - Recreation: 200 docs
    - Science: 200 docs
    - Politics/Religion: 200 docs
    - Miscellaneous: 200 docs

================================================================================
Running CTE Topic Model (K=5 topics, 10 keywords)
================================================================================

Loading all-MiniLM-L6-v2 embeddings...
Computing document embeddings...
Batches:   0%|          | 0/32 [00:00<?, ?it/s]Batches:   3%|▎         | 1/32 [00:00<00:17,  1.77it/s]Batches:   6%|▋         | 2/32 [00:01<00:15,  1.88it/s]Batches:   9%|▉         | 3/32 [00:01<00:15,  1.89it/s]Batches:  12%|█▎        | 4/32 [00:02<00:14,  1.94it/s]Batches:  16%|█▌        | 5/32 [00:02<00:14,  1.91it/s]Batches:  19%|█▉        | 6/32 [00:03<00:13,  1.94it/s]Batches:  22%|██▏       | 7/32 [00:03<00:12,  1.94it/s]Batches:  25%|██▌       | 8/32 [00:04<00:12,  1.95it/s]Batches:  28%|██▊       | 9/32 [00:04<00:11,  1.95it/s]Batches:  31%|███▏      | 10/32 [00:05<00:11,  1.96it/s]Batches:  34%|███▍      | 11/32 [00:05<00:10,  1.98it/s]Batches:  38%|███▊      | 12/32 [00:06<00:10,  1.97it/s]Batches:  41%|████      | 13/32 [00:06<00:09,  1.97it/s]Batches:  44%|████▍     | 14/32 [00:07<00:08,  2.11it/s]Batches:  47%|████▋     | 15/32 [00:07<00:07,  2.13it/s]Batches:  50%|█████     | 16/32 [00:08<00:07,  2.02it/s]Batches:  53%|█████▎    | 17/32 [00:08<00:06,  2.30it/s]Batches:  56%|█████▋    | 18/32 [00:08<00:05,  2.61it/s]Batches:  59%|█████▉    | 19/32 [00:08<00:04,  2.78it/s]Batches:  62%|██████▎   | 20/32 [00:09<00:04,  2.99it/s]Batches:  66%|██████▌   | 21/32 [00:09<00:03,  3.44it/s]Batches:  69%|██████▉   | 22/32 [00:09<00:02,  3.95it/s]Batches:  72%|███████▏  | 23/32 [00:09<00:02,  4.11it/s]Batches:  75%|███████▌  | 24/32 [00:09<00:01,  4.67it/s]Batches:  78%|███████▊  | 25/32 [00:10<00:01,  4.79it/s]Batches:  81%|████████▏ | 26/32 [00:10<00:01,  4.78it/s]Batches:  88%|████████▊ | 28/32 [00:10<00:00,  6.48it/s]Batches:  91%|█████████ | 29/32 [00:10<00:00,  6.60it/s]Batches: 100%|██████████| 32/32 [00:10<00:00,  2.97it/s]
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"

Tokenizing texts...
Building keyword embedding map...
  Total unique words: 16214

Fitting CTE model...
[WARNING] Failed to initialize evaluators: No module named 'newsgroup.StatEvaluator'
[DEBUG] CTE 모델 학습 시작 (총 1000개 문서)
[DEBUG] 클러스터링 수행 중...
[DEBUG] 벡터라이저 초기화 중...
[DEBUG] TF-IDF 행렬 생성 중...
[DEBUG] 단어 빈도 계산 중...
[DEBUG] Extracting topic keywords with batched processing...
[DEBUG] Embeddings shape: torch.Size([1000, 384])
[DEBUG] Processing topic 1/5
[DEBUG] Processing topic 2/5
[DEBUG] Processing topic 3/5
[DEBUG] Processing topic 4/5
[DEBUG] Processing topic 5/5
[DEBUG] CTE 모델 학습 완료

Extracted 5 topics:
  Topic 1: canucks, braves, bullpen, cubs, baseman, baseball, divisional, baseballs, bruins, dodgers
  Topic 2: cheap, cost, cheaply, cheapest, deals, auction, bids, costs, budget, buy
  Topic 3: ebcdic, dxcomm, aixwindows, amigavision, bcmp, cplab, cstom, cxm, dos, digitized
  Topic 4: condemning, atheism, advocating, contradictions, blindly, disbelievers, contradictory, contemptibly, dissent, debated
  Topic 5: chipset, chipsets, amigavision, dell, cdware, cheap, compat, cheapest, emulator, amiga

================================================================================
Statistical Evaluation (NPMI, JSD, TD)
================================================================================

Statistical Results:
  Coherence (NPMI): 0.872
  Distinctiveness (JSD): 0.116
  Diversity (TD): 0.940

================================================================================
Semantic Evaluation (Embedding-based)
================================================================================
[INFO] Using dynamic embedding mode for 20 Newsgroups keywords

Semantic Results:
  Coherence: 0.423
  Distinctiveness: 0.308
  Diversity: 0.637

================================================================================
LLM Evaluation (OpenAI, Anthropic, Grok)
================================================================================

================================================================================
Evaluating with OpenAI
================================================================================
[INFO] Using OpenAI for LLM evaluation
[INFO] Evaluating 5 topics with 10 keywords each


=== Evaluating 20 Newsgroups Topics (OpenAI) ===

Evaluating Coherence...
Coherence Score: 0.680
Explanation: Most topics display moderate to strong internal coherence, but a few have issues that lower the overall score:

- **Topic 1**: Words are strongly related to baseball and sports teams, with a clear and interpretable theme. High coherence.
- **Topic 2**: All words relate to affordability, pricing, and purchasing, forming a clear theme. High coherence.
- **Topic 3**: This topic is less coherent. While most words are related to computing or software (often obscure or technical), the connections are weaker and less interpretable as a single theme.
- **Topic 4**: Words are semantically related to debate, criticism, and atheism, forming a moderately coherent theme around argumentation and belief


Evaluating Distinctiveness...
Distinctiveness Score: 0.720
Explanation: While most topics are clearly distinct, there is some overlap that reduces the overall distinctiveness. Here’s the breakdown:

- Topic 1 (sports/baseball) and Topic 2 (cost/deals) are highly distinct from each other, with no semantic overlap.
- Topic 3 (technical/computing terms) is also quite distinct from both sports and cost topics, though "amigavision" appears in both Topic 3 and Topic 5, indicating some overlap.
- Topic 4 (philosophy/atheism/debate) is thematically unique and does not overlap with the other topics.
- Topic 5 (computer hardware/software, especially Amiga-related) overlaps with Topic 3 (both mention


Evaluating Diversity...
Diversity Score: 0.820
Explanation: The topic set demonstrates strong diversity. The topics cover a wide range of themes: sports (Topic 1), economics/shopping (Topic 2), computing/technology (Topic 3), philosophy/religion/debate (Topic 4), and hardware/technology (Topic 5). There is good semantic variation, with most topics focusing on distinct subject areas. However, there is some minor overlap between Topics 3 and 5, both of which relate to technology and computing, and a slight connection between Topics 2 and 5 through the words "cheap" and "cheapest." Despite this, the overall coverage is broad, and the topics are generally well-balanced and non-redundant, supporting a high diversity


Evaluating Semantic Integration...
Semantic Integration Score: 0.620
Explanation: The semantic integration of this topic model is moderate. Here’s the breakdown:

1. **Overall topic model coherence:**  
Most topics are internally coherent. Topic 1 (sports/baseball teams) and Topic 2 (cost/cheapness) are especially strong. Topic 4 (atheism, debate) is also coherent. However, Topic 3 (technical terms, file formats, platforms) and Topic 5 (hardware, software, some overlap with Topic 2 and 3) are less clear, with some word overlap (e.g., "amigavision" appears in both 3 and 5, "cheap" in 2 and 5), which reduces overall coherence.

2. **Balance between

Overall Score: 0.708
==================================================

OpenAI Results:
  Coherence: 0.680
  Distinctiveness: 0.720
  Diversity: 0.820

================================================================================
Evaluating with Anthropic
================================================================================
[INFO] Using Anthropic for LLM evaluation
[INFO] Evaluating 5 topics with 10 keywords each


=== Evaluating 20 Newsgroups Topics (Anthropic) ===

Evaluating Coherence...
Coherence Score: 0.620
Explanation: **Explanation:**

**Topic-by-Topic Analysis:**

1. **Topic 1 (Sports)** - Coherence: 0.95
   - Highly coherent with clear baseball/sports theme (canucks, braves, cubs, dodgers are teams; bullpen, baseman, baseball are sport-specific terms)
   - Minor note: "bruins" (hockey) slightly diverges but still sports-related

2. **Topic 2 (Economics/Shopping)** - Coherence: 0.90
   - Very strong coherence around cost and purchasing (cheap, cost, deals, auction, bids, budget, buy)


Evaluating Distinctiveness...
Distinctiveness Score: 0.720
Explanation: ## Explanation:

**Strengths in Differentiation:**

1. **Clear Thematic Separation (Topics 1, 2, 4):**
   - Topic 1 is distinctly about sports (baseball/hockey teams and terminology)
   - Topic 2 focuses clearly on pricing and purchasing
   - Topic 4 addresses philosophical debate and criticism
   - These three topics have virtually no semantic overlap

2. **Unique Vocabulary:**
   - Most topics contain domain-specific terminology that clearly distinguishes them
   - Topic 1: team names (Canucks, Braves, Cubs, Do


Evaluating Diversity...
Diversity Score: 0.550
Explanation: ## Explanation:

**Strengths:**
1. **Distinct thematic clusters exist**: Topic 1 (sports/baseball), Topic 2 (pricing/commerce), and Topic 4 (religious/philosophical debate) represent clearly different semantic domains
2. **Broad conceptual range**: The topics span from concrete (sports teams, computer hardware) to abstract (philosophical arguments)

**Weaknesses:**

1. **Significant overlap between Topics 3 and 5**: Both contain technical/computer terminology (amigavision, chipset, emulator, dos, amiga). This represents ~40% redundancy in the topic set


Evaluating Semantic Integration...
Semantic Integration Score: 0.420
Explanation: ## Explanation:

### Strengths:
1. **Clear Distinctiveness (0.7)**: Topics 1 (sports), 2 (pricing/commerce), and 4 (religious debate) are well-separated with minimal overlap
2. **Internal Coherence - Partial (0.5)**: Topics 1, 2, and 4 show reasonable internal consistency within their domains

### Significant Weaknesses:

1. **Poor Topic Quality (0.3)**:
   - **Topic 3** is essentially noise - a collection of technical jargon, system names, and acronyms without

Overall Score: 0.596INFO:httpx:HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"

==================================================

Anthropic Results:
  Coherence: 0.620
  Distinctiveness: 0.720
  Diversity: 0.550

================================================================================
Evaluating with Grok
================================================================================
[INFO] Using Grok for LLM evaluation
[INFO] Evaluating 5 topics with 10 keywords each


=== Evaluating 20 Newsgroups Topics (Grok) ===

Evaluating Coherence...
Coherence Score: 0.800
Explanation: The topics demonstrate strong overall semantic coherence, with most forming clear and interpretable themes based on word relationships. Topic 1 revolves around sports (primarily baseball teams and terms, with some hockey overlap like "canucks" and "bruins"), showing good consistency but minor mixing of sub-themes. Topic 2 is highly coherent around affordability and purchasing (e.g., "cheap," "deals," "auction"). Topic 3 clusters technical/computing terms (e.g., "ebcdic," "dos," "digitized"), but some obscure acronyms reduce clarity and consistency. Topic 4 clearly themes around debate, criticism, and atheism (e.g., "condemning," "contradictions," "dissent"). Topic 5 focuses on computer hardware and software with affordability elements (e.g., "chipset," "amiga," "cheap"), maintaining solid internal relations. The score reflects high coherence across the set, deducted slightly for inconsistencies in Topics 1 and 3.


Evaluating Distinctiveness...
Distinctiveness Score: 0.750
Explanation: The topics demonstrate a good level of distinctiveness overall, with clear unique thematic focuses: Topic 1 centers on sports (e.g., baseball teams and terms), Topic 2 on affordability and purchasing (e.g., costs and deals), Topic 3 on older computing and software concepts (e.g., EBCDIC, DOS), Topic 4 on philosophical or debate-related ideas (e.g., atheism, contradictions), and Topic 5 on computer hardware and emulation (e.g., chipsets, Amiga). Boundaries are mostly clear, with minimal semantic overlap across the majority of pairs. However, there is moderate overlap between Topics 3 and 5 (shared word "amigavision" and a common retro computing theme) and between Topics 2 and 5 (shared words "cheap" and "cheapest," introducing some affordability semantics into tech). This reduces perfect separation but does not make topics redundant, resulting in strong but not complete distinctiveness.


Evaluating Diversity...
Diversity Score: 0.750
Explanation: The topic set demonstrates good overall diversity, covering a range of themes including sports (Topic 1), economics and purchasing (Topic 2), vintage computing and software (Topic 3), philosophical or religious debate (Topic 4), and hardware/emulation technology (Topic 5). This provides solid semantic range and variation across unrelated concepts like athletics, finance, technology, and ideology. The distribution is reasonably balanced with five topics, each focusing on distinct areas, which helps avoid heavy skew toward any single domain. However, diversity is somewhat reduced by overlaps and redundancies: Topics 3 and 5 both emphasize computing elements (e.g., "amigavision" appears in both, and both touch on retro tech like Amiga and DOS), while Topic 5 shares cost-related terms ("cheap," "cheapest") with Topic 2. These redundancies limit the absence of overlapping topics, preventing a higher score, but the set still achieves broad coverage without excessive repetition.


Evaluating Semantic Integration...
Semantic Integration Score: 0.650
Explanation: The overall semantic integration of this topic model is moderate, scoring 0.65 due to a mix of strengths and weaknesses across the evaluation criteria. For overall topic model coherence, Topics 1 (sports/baseball-related terms), 2 (bargain shopping and economics), and 4 (philosophical or religious debate) show strong internal relatedness, with words clustering logically around clear themes. However, Topics 3 and 5 are less coherent; Topic 3 appears as a jumble of outdated computing terms (e.g., EBCDIC, DOS, AmigaVision) without a tight unifying concept, and Topic 5 mixes hardware (chipset, Dell) with software/emulation terms and economic words (cheap, cheapest), leading to some fragmentation. On balance between distinctiveness and relationships, the topics are generally distinct—e.g., sports in Topic 1 versus debate in Topic 4—but overlaps like "amigavision" appearing in both Topics 3 and 5, and "cheap/cheapest" in Topics 2 and 5, introduce redundancy and blur boundaries, reducing semantic separation. Hierarchical topic structure is weak; there's no evident nesting or progression (e.g., Topics 3 and 5 could potentially form a subtree under "vintage computing," but they remain flat and disconnected). Finally, practical interpretability and usefulness are fair for applied scenarios like document clustering or recommendation systems, as Topics 1, 2, and 4 are easily labeled and actionable, but the noise and overlaps in Topics 3 and 5 could hinder real-world utility, such as in search engines or content analysis, where clearer delineations would improve precision. Overall, the model integrates semantics reasonably well but could be refined for better cohesion and minimal overlap to reach excellence.

Overall Score: 0.745
==================================================

Grok Results:
  Coherence: 0.800
  Distinctiveness: 0.750
  Diversity: 0.750

================================================================================
Average LLM Results
================================================================================
  Coherence: 0.700
  Distinctiveness: 0.730
  Diversity: 0.707

================================================================================
INDIVIDUAL LLM RESULTS
================================================================================

LLM                Coherence    Distinct.    Diversity      Overall
---------------------------------------------------------------
OpenAI                 0.680        0.720        0.820        0.720
Anthropic              0.620        0.720        0.550        0.636
Grok                   0.800        0.750        0.750        0.775

================================================================================
FINAL RESULTS: Manuscript Table X
================================================================================

Method                  Coherence    Distinct.    Diversity      Overall   Δ from LLM
--------------------------------------------------------------------------------------------
Statistical                 0.872        0.116        0.940        0.659        0.052
Semantic                    0.423        0.308        0.637        0.432        0.279
LLM Baseline (Avg)          0.700        0.730        0.707        0.710            —

Weights: Coherence (0.5), Distinctiveness (0.3), Diversity (0.2)
Proximity: Δ = |Method Score - LLM Average Score|

================================================================================
KEY FINDING
================================================================================

Statistical evaluation aligns better with LLM baseline
  Statistical Δ = 0.052
  Semantic Δ = 0.279

================================================================================
Experiment Complete
================================================================================
