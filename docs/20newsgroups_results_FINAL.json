{
  "dataset": {
    "name": "20 Newsgroups",
    "num_documents": 18846,
    "num_categories": 20,
    "categories": [
      "alt.atheism",
      "comp.graphics",
      "comp.os.ms-windows.misc",
      "comp.sys.ibm.pc.hardware",
      "comp.sys.mac.hardware",
      "comp.windows.x",
      "misc.forsale",
      "rec.autos",
      "rec.motorcycles",
      "rec.sport.baseball",
      "rec.sport.hockey",
      "sci.crypt",
      "sci.electronics",
      "sci.med",
      "sci.space",
      "soc.religion.christian",
      "talk.politics.guns",
      "talk.politics.mideast",
      "talk.politics.misc",
      "talk.religion.misc"
    ]
  },
  "model": {
    "type": "LDA",
    "num_topics": 20,
    "vocabulary_size": 5000,
    "iterations": 1000
  },
  "statistical_metrics": {
    "perplexity": -14.328699914769013,
    "umass_coherence": -3.3059349298972998,
    "topic_diversity": 0.99,
    "umass_coherence_per_topic": {
      "mean": -2.443723259680532,
      "std": 0.5076131370763269,
      "range": [
        -3.590586373655492,
        -1.4160084302012848
      ],
      "values": [
        -2.349033186613026,
        -3.4617312966894462,
        -2.785189547134979,
        -2.815382443949174,
        -2.313005869270542,
        -1.7259157272357202,
        -2.2948688945604023,
        -2.089569368100414,
        -2.1775261205048206,
        -3.590586373655492,
        -2.2949385619468003,
        -1.4160084302012848,
        -2.8319781821512837,
        -2.346400999715367,
        -2.7693545385527005,
        -2.2717592837558978,
        -2.6407893812683065,
        -2.349548431259035,
        -2.5082307553952456,
        -1.8426478016506977
      ]
    }
  },
  "semantic_metrics": {
    "semantic_coherence": 0.30911174781180095,
    "semantic_distinctiveness": 0.27579342708708765,
    "semdiv": 0.2924525874494443,
    "semantic_coherence_per_topic": {
      "mean": 0.30911174781180095,
      "std": 0.042768841755847005,
      "range": [
        0.2445040155172567,
        0.42596185770851547
      ],
      "values": [
        0.32467528092527626,
        0.2445040155172567,
        0.2611542358913799,
        0.2864451977844401,
        0.27274365437798553,
        0.3458869931047739,
        0.3297452693377117,
        0.32875343870968304,
        0.3050108922032237,
        0.25124051653505786,
        0.30070993458243944,
        0.3430839013440649,
        0.26894034369079833,
        0.29167178153322737,
        0.42596185770851547,
        0.33693274430380055,
        0.2873601387012761,
        0.2847483677951636,
        0.3229582112683414,
        0.3697081809216034
      ]
    }
  },
  "ground_truth": {
    "avg_category_purity": 0.4262371753453692,
    "purity_range": [
      0.0,
      1.0
    ],
    "topic_purities": [
      0.48717948717948717,
      0.42857142857142855,
      1.0,
      0.5,
      0.6666666666666666,
      0.10823689584751532,
      0.15625,
      0.6451612903225806,
      0.23745819397993312,
      0.9302325581395349,
      0.14241001564945227,
      0.16573033707865167,
      0.6875,
      0.2222222222222222,
      0.2761904761904762,
      0.5,
      0.5,
      0.0,
      0.8,
      0.07090301003344482
    ]
  },
  "correlations": {
    "umass_vs_purity": {
      "r": -0.5731243965008027,
      "p": 0.008252236359950562,
      "interpretation": "moderate"
    },
    "semantic_coherence_vs_purity": {
      "r": -0.46829065694398064,
      "p": 0.03730132434496586,
      "interpretation": "moderate"
    },
    "improvement": {
      "absolute": 0.10483373955682207,
      "relative_percent": 18.291620492319286
    }
  }
}